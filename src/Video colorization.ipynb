{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Video colorizer, it is colorize in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, BatchNormalization, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Flatten\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from skimage import color\n",
    "import warnings\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# Import own .py files\n",
    "import data_collector\n",
    "import image_loader\n",
    "from nnetwork import weighted_categorical_crossentropy\n",
    "import nnetwork\n",
    "from utility_methods import save_plots\n",
    "from importlib import reload  # Python 3.4+ only.\n",
    "nnetwork = reload(nnetwork)\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you need trained weights. After training you can load up in here, and start the colorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weights = 'O:/ProgrammingSoftwares/anaconda_projects/dp_nagyhazi/tests/20181204_b_model/weights.hdf5'\n",
    "root_pictures = 'O:/ProgrammingSoftwares/anaconda_projects/dp_nagyhazi/tests/20181204_b_model/test_pics/'\n",
    "image_folder = 'O:/ProgrammingSoftwares/anaconda_projects/dp_nagyhazi/samples/images/'\n",
    "distrib = np.load('O:/ProgrammingSoftwares/anaconda_projects/dp_nagyhazi/data/prior_probs.npy')\n",
    "los = weighted_categorical_crossentropy(distrib,lmb=0.5)\n",
    "model = keras.models.load_model(test_weights, custom_objects={'loss': los})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "O:\\ProgrammingSoftwares\\anaconda3\\envs\\tensor-cpu\\lib\\site-packages\\keras_preprocessing\\image.py:836: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of image list:  28\n"
     ]
    }
   ],
   "source": [
    "import streaming_data\n",
    "streaming_data = reload(streaming_data)\n",
    "\n",
    "watcher = streaming_data.StreamingDataGenerator(image_folder,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video file thread...\n"
     ]
    }
   ],
   "source": [
    "from imutils.video import FileVideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "from skimage import color\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform, io, color\n",
    "\n",
    "#out = cv2.VideoWriter('output.avi', -1, 20.0, (224,224))\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#out = cv2.VideoWriter('outpy.avi',fourcc, 10, (224,224))\n",
    "\n",
    "# The video file should be next to this notebook.\n",
    "filename = 'landscape2.mp4'\n",
    "\n",
    "print(\"[INFO] starting video file thread...\")\n",
    "fvs = FileVideoStream(filename).start()\n",
    "time.sleep(1.0)\n",
    " \n",
    "# start the FPS timer\n",
    "fps = FPS().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "O:\\ProgrammingSoftwares\\anaconda3\\envs\\tensor-cpu\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] elasped time: 85.11\n",
      "[INFO] approx. FPS: 1.21\n"
     ]
    }
   ],
   "source": [
    "# loop over frames from the video file stream\n",
    "while fvs.more():\n",
    "    # grab the frame from the threaded video file stream, resize\n",
    "    # it, and convert it to grayscale (while still retaining 3\n",
    "    # channels)\n",
    "    frame = fvs.read()\n",
    "    frame = imutils.resize(frame, width=450)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = np.dstack([frame, frame, frame])\n",
    "    frame = transform.resize(frame , (224,224), preserve_range=False)\n",
    "    #print(frame)\n",
    "    \n",
    "    frame2 = pred_image(model, frame, watcher)\n",
    "    #print(np.max(frame2))\n",
    "    # display the size of the queue on the frame\n",
    "    #cv2.putText(frame2[0], \"Queue Size: {}\".format(fvs.Q.qsize()),(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    # show the frame and update the FPS counter\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame2)\n",
    "    #out.write(frame2)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    fps.update()\n",
    "\n",
    "# stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "fvs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_image(model, X, watcher, Y = None):\n",
    "    X = X.reshape((1,224,224,3))*255\n",
    "    inp = X - np.mean(X)\n",
    "    #plt.imshow(X[0]/255)\n",
    "    #plt.show()\n",
    "    y_real = model.predict(inp)\n",
    "    if (Y is not None):\n",
    "        y_real = Y\n",
    "\n",
    "    # Choose the a-b colors from the color classes.\n",
    "    y_real = np.apply_along_axis(lambda x: watcher.pts_in_hull[np.argmax(x)], axis=3, arr = y_real)[0]\n",
    "    lightness_3 = transform.resize( X[0] , (56,56), preserve_range=True)\n",
    "    #print(np.min(y_real[:,:,1]))\n",
    "    #print(np.max(y_real[:,:,1]))\n",
    "\n",
    "    lab_im = np.concatenate([lightness_3[:,:,0,np.newaxis]/255*100, y_real[:,:,0,np.newaxis],y_real[:,:,1,np.newaxis]], axis = 2)\n",
    "    \n",
    "    rgb_img = color.lab2rgb(lab_im)\n",
    "    rgb_img = transform.resize( rgb_img , (224,224), preserve_range=False)\n",
    "    lab_im = color.rgb2lab(rgb_img)\n",
    "    lab_im = np.concatenate([ X[0,:,:,0,np.newaxis]/255*100, lab_im[:,:,1,np.newaxis],lab_im[:,:,2,np.newaxis]], axis = 2)\n",
    "\n",
    "    rgb_img = color.lab2rgb(lab_im)\n",
    "    \n",
    "    return rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensor-cpu]",
   "language": "python",
   "name": "conda-env-tensor-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
